{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Toppa @ Berkeley 2019 Data Team Homework 3\n",
    "The dataset used for this homework is taken from Avazu's CTR Prediction Dataset on Kaggle.  \n",
    "Your task is to fill out all the places marked with #TODO or #YOUR CODE HERE.  \n",
    "This codebase is taken from @susanli's solution, with small modifications.  \n",
    "\n",
    "Author: Vincent, @susanli  \n",
    "Your name:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "def parse_date(val): return pd.datetime.strptime(val, '%y%m%d%H')\n",
    "\n",
    "train = pd.read_csv(\"modified_data/train_100000\", parse_dates=['hour'], date_parser=parse_date)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: EDA\n",
    "Please perform some basic exploratory data analysis.  \n",
    "Specifically, please at least plot **5** different graphs, and __report your findings in a short markdown block__.\n",
    "Some potential options include:\n",
    "1. Number of clicks per hour/day\n",
    "2. Banner position vs. Click rate\n",
    "3. Site ids vs. Click rate\n",
    "4. Device id vs. Click rate\n",
    "5. etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Feature Engineering\n",
    "Now that you have a basic understanding of the dataset, we can start doing feature engineering.  \n",
    "Step 1: Please complete the function convert_obj_to_int(). For this step, you only need to write one line.  \n",
    "Step 2: Drop 'hour' and 'id' columns as they are not so important.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_obj_to_int(self):\n",
    "    '''\n",
    "    This function takes in a dataframe with mixed dtype, and return a dataframe with only int as its datatype.\n",
    "    Essentially, this function transforms the columns with object data type into columns with int.\n",
    "    Your task here is to implement a lambda function that maps an object to an integer.\n",
    "    HINT: How did you solve the room number puzzle again?\n",
    "    '''\n",
    "\n",
    "    object_list_columns = self.columns  # Get a list of columns of the dataframe\n",
    "    object_list_dtypes = self.dtypes  # Get a list of dtypes\n",
    "    new_col_suffix = '_int'  # adding a suffix to new columns\n",
    "\n",
    "    for index in range(0, len(object_list_columns)):\n",
    "        if object_list_dtypes[index] == object:\n",
    "            self[object_list_columns[index] +\n",
    "                 new_col_suffix] = self[object_list_columns[index]].map(#YOUR CODE HERE) \n",
    "            self.drop([object_list_columns[index]], inplace=True, axis=1) # Dropping the original object column\n",
    "\n",
    "    return self\n",
    "\n",
    "\n",
    "train = convert_obj_to_int(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: drop unneeded columns\n",
    "train.drop('hour', axis=1, inplace=True)\n",
    "train.drop('id', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, you should pretty much have a dataframe that looks like the one in data.csv. \n",
    "If it's not (or you're not so confident about your implementation, feel free to just read data.csv as your engineered data for the training process below)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment the following line to use my feature engineered dataset\n",
    "# train = pd.read_csv(\"data.csv\")\n",
    "# train.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "# train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting useful features\n",
    "features = ['C1', 'banner_pos', 'device_type', 'device_conn_type', 'C14',\n",
    "       'C15', 'C16', 'C17', 'C18', 'C19', 'C20', 'C21', 'hour_of_day',\n",
    "       'site_id_int', 'site_domain_int', 'site_category_int', 'app_id_int',\n",
    "       'app_domain_int', 'app_category_int', 'device_id_int', 'device_ip_int',\n",
    "       'device_model_int', 'day_of_week_int']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Model Construction\n",
    "Now it's time to start building your own model!\n",
    "Here are some models we are trying out for this hw:\n",
    "1. LGBM\n",
    "2. Logistic Regressions\n",
    "\n",
    "For LGBM, it is a class of gradient boosted ensemble tree models; feel free to read more about it if you have the time.   \n",
    "For logistic regression, we can just use the implementation in sklearn.   \n",
    "__Please install LGBM if you haven't already.__  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing LGB model. No need to modify this code.\n",
    "\n",
    "import lightgbm as lgb\n",
    "X_train = train.loc[:, train.columns != 'click']\n",
    "y_target = train.click.values\n",
    "\n",
    "# create lightgbm dataset\n",
    "msk = np.random.rand(len(X_train)) < 0.8\n",
    "lgb_train = lgb.Dataset(X_train[msk], y_target[msk])\n",
    "lgb_eval = lgb.Dataset(X_train[~msk], y_target[~msk], reference=lgb_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Intro to Tuning Hyperparameters\n",
    "The model implementation of LGBM is already given here.  \n",
    "All you need to do is to play around with the model hyperparameters. See if you can arrive at an optimal model.  \n",
    "When you're done please report your findings (e.g. which hyperparameter \"matters\" the most to model accuracy?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify your configurations as a dict\n",
    "params = {\n",
    "    'task': 'train',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'binary',\n",
    "    'metric': { 'binary_logloss'},\n",
    "    'num_leaves': 31, # defauly leaves(31) amount for each tree\n",
    "    'learning_rate': 0.08,\n",
    "    'feature_fraction': 0.7, # will select 70% features before training each tree\n",
    "    'bagging_fraction': 0.3, #feature_fraction, but this will random select part of data\n",
    "    'bagging_freq': 5, #  perform bagging at every 5 iteration\n",
    "    'verbose': 0\n",
    "}\n",
    "\n",
    "print('Start training...')\n",
    "# train\n",
    "gbm = lgb.train(params,\n",
    "                lgb_train,\n",
    "                num_boost_round=4000,\n",
    "                valid_sets=lgb_eval,\n",
    "                early_stopping_rounds=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(gbm.best_score)\n",
    "print(gbm.best_iteration)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (Optional) Run the dataset with Xgboost\n",
    "\n",
    "XGBOOST is a similar framework, feel free to play around with it and report your findings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "from sklearn.model_selection import train_test_split\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "def run_default_test(train, test, features, target, random_state=0):\n",
    "    eta = 0.1\n",
    "    max_depth = 5\n",
    "    subsample = 0.8\n",
    "    colsample_bytree = 0.8\n",
    "    print('XGBoost params. ETA: {}, MAX_DEPTH: {}, SUBSAMPLE: {}, COLSAMPLE_BY_TREE: {}'.format(\n",
    "        eta, max_depth, subsample, colsample_bytree))\n",
    "    params = {\n",
    "        \"objective\": \"binary:logistic\",\n",
    "        \"booster\": \"gbtree\",\n",
    "        \"eval_metric\": \"logloss\",\n",
    "        \"eta\": eta,\n",
    "        \"max_depth\": max_depth,\n",
    "        \"subsample\": subsample,\n",
    "        \"colsample_bytree\": colsample_bytree,\n",
    "        \"silent\": 1,\n",
    "        \"seed\": random_state\n",
    "    }\n",
    "    num_boost_round = 260\n",
    "    early_stopping_rounds = 20\n",
    "    test_size = 0.2\n",
    "\n",
    "    X_train, X_valid = train_test_split(\n",
    "        train, test_size=test_size, random_state=random_state)\n",
    "    y_train = X_train[target]\n",
    "    y_valid = X_valid[target]\n",
    "    dtrain = xgb.DMatrix(X_train[features], y_train)\n",
    "    dvalid = xgb.DMatrix(X_valid[features], y_valid)\n",
    "    watchlist = [(dtrain, 'train'), (dvalid, 'eval')]\n",
    "    gbm = xgb.train(params, dtrain, num_boost_round, evals=watchlist,\n",
    "                    early_stopping_rounds=early_stopping_rounds, verbose_eval=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_default_test(train, y_target, features, 'click')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression\n",
    "Now it's time to do logistic regression as we've learned in lecture!\n",
    "Here are the steps:\n",
    "1. First you want to do a train test split. Notice that all you currently have is the train dataframe. You might want to split it into X_train and X_valid (for validation/testing).  \n",
    "2. Since label data is already included in train dataframe, let's assign the 'click' column of X_train, X_valid to y_train, y_valid.   \n",
    "3. Now since we've already done feature engineering, let's only use our selected features for X_train and X_valid.  \n",
    "4. Now it's time to initialize a Logistic Regression model from sklearn and call the fit function!\n",
    "5. Run the last function, model.score to see your model accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "\n",
    "# Train Test Split\n",
    "X_train, X_valid =  # TODO\n",
    "\n",
    "# Create Labels\n",
    "y_train, y_valid =  # TODO\n",
    "\n",
    "# Select important features\n",
    "X_train, X_valid =  # TODO\n",
    "\n",
    "# Initialize a logistic regression model\n",
    "model =  # TODO\n",
    "model.fit()  # TODO\n",
    "\n",
    "# Getting predictions\n",
    "y_pred = model.predict(X_valid)\n",
    "\n",
    "print('Accuracy of logistic regression classifier on test set: {:.2f}'.format(\n",
    "    model.score(X_valid, y_valid)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix = confusion_matrix(y_valid, y_pred)\n",
    "print(confusion_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute precision & recall\n",
    "\n",
    "The precision is the ratio tp / (tp + fp) where tp is the number of true positives and fp the number of false positives. The precision is intuitively the ability of the classifier not to label as positive a sample that is negative.\n",
    "\n",
    "The recall is the ratio tp / (tp + fn) where tp is the number of true positives and fn the number of false negatives. The recall is intuitively the ability of the classifier to find all the positive samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_valid, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ROC Curve\n",
    "\n",
    "Let's plot a ROC curve to see how our model is actually performing!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "logit_roc_auc = roc_auc_score(y_valid, logreg.predict(X_valid))\n",
    "fpr, tpr, thresholds = roc_curve(y_valid, logreg.predict_proba(X_valid)[:,1])\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, label='Logistic Regression (area = %0.2f)' % logit_roc_auc)\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.savefig('Log_ROC')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Congrats! Now you have what it takes to complete the data team project!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
